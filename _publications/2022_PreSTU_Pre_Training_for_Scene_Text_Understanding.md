---
title: "PreSTU: Pre-Training for Scene-Text Understanding"
collection: publications
permalink: /publication/2022_PreSTU_Pre_Training_for_Scene_Text_Understanding
excerpt: 'We propose PreSTU, a simple pre-training recipe specifically designed for scene-text understanding.'
date: 2022-09-13
author: '*Jihyung Kil, Soravit Changpinyo, **Xi Chen**, Hexiang Hu, Sebastian Goodman, Wei-Lun Chao, Radu Soricut*'
venue: 'arXiv:2209.05534 (2022)'
paperurl: 'https://arxiv.org/abs/2209.05534'

---

The ability to read and reason about texts in an image is often lacking in vision-and-language (V&L) models. How can we learn V&L models that exhibit strong scene-text understanding (STU)? In this paper, we propose PreSTU, a simple pre-training recipe specifically designed for scene-text understanding. PreSTU combines a simple OCR-aware pre-training objective with a large-scale image-text dataset with off-the-shelf OCR signals. We empirically demonstrate the superiority of this pre-training objective on TextVQA, TextCaps, ST-VQA, and VizWiz-VQA. We also study which factors affect STU performance, where we highlight the importance of image resolution and dataset scale during pre-training.

[Access the paper here](https://arxiv.org/abs/2209.05534)
